---
title: "R Notebook"
output: github_document
---
# DADA2 PIPELINE
Pipeline complet DADA2 pour l’analyse de données de séquençage 16S (issu du MiSeq SOP) en identifiant les variantes de séquences d'amplicons (ASV) par modélisation des erreurs

## Preparation
Activation de la librairie dada2 après installation du package :
Vérification de la version du package dada2 :
```{r, cache=TRUE}
library(dada2)
packageVersion("dada2")
```
Définition du répertoire (path) contenant les fichiers fastq (=résultats de séquençage d'amplicons 2x250 Illumina Miseq de la région V4 du gène de l'ARN 16S d'échantillons fécaux d'intestins de souris post-sevrage) et vérification de leur présence dans le dossier (list.files) :
```{r, cache=TRUE}
path <- "~/tutoriel_ADM/MiSeq_SOP"
list.files(path)
```
Chaque échantillon possède un R1 (lecture forward) et R2 (lecture reverse)


Création de deux listes : reads forward (_R1_ -> fnFs) et reverse (_R2_ -> fnRs)
Et extraction du nom des échantillons à partir du nom des fichiers (SAMPLENAME_XXX.fastq) :
```{r, cache=TRUE}
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))#Liste lecture forward
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))#Liste lecture reverse
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```


## Vérification de la qualité des séquences 

Ces graphes permettent de visualiser les scores de qualité des reads et de déterminer où tronquer les séquences pour éliminer les bases de mauvaise qualité en fin de lecture.
Visualisation du profil de qualité des forward reads :
```{r, cache=TRUE}
plotQualityProfile(fnFs[1:2])
```
Les forward reads sont de bonne qualité -> très peu de tronquage (trimming) est nécessaire (10 dernières nucléotides).

Visualisation du profil de qualité des séquences reverse :
```{r, cache=TRUE}
plotQualityProfile(fnRs[1:2])
```
Les reads reverse sont de plus mauvaise qualité que les forward et nécessiteront un tronquage plus important (90 dernières nucléotides).


## Filtrage et tronquage des séquences

Les fichiers filtrés sont compressés et enregistrés dans le dossier "filtered" :
```{r, cache=TRUE}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

Application de critères de qualité (maxN=0, truncQ=2, rm.phix=TRUE et maxEE=2) pour supprimer les reads trop courts ou de mauvaise qualité :
truncLen=c(240,160) : garde seulement les 240 premières bases en forward et 160 en reverse
maxN=0 : aucune base indéterminée (‘N’) tolérée
maxEE=c(2,2) : tolère au maximum 2 erreurs attendues par read
truncQ=2 : tronque quand la qualité descend sous Q=2
rm.phix=TRUE : supprime les contaminations PhiX
```{r, cache=TRUE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE)
head(out)
```

## Apprentissage des erreurs de séquençage

Estimation des taux d’erreurs appris à partir des reads forward et reverse donnés (err = modèle d'erreurs paramétriques) :
Etape cruciale pour distinguer erreurs de séquençage et les vraies variantes
```{r, cache=TRUE}
errF <- learnErrors(filtFs, multithread=TRUE)#Taux d'erreurs des reads forward
```

```{r, cache=TRUE}
errR <- learnErrors(filtRs, multithread=TRUE)#Taux d'erreurs des reads reverse
```
Visualisation des modèles d’erreurs appris (forward) :
```{r, cache=TRUE}
plotErrors(errF, nominalQ=TRUE)
```
Ici, les taux d'erreurs estimés (ligne noire) correspondent au taux osbervés (points) : les taux d'erreurs diminuent bien quand le score de qualité augmente.

## Denoising : identification des variantes de séquences (ASV)

Application des modèles d’erreurs pour corriger les reads et identifier les séquences uniques réelles (ASV) (chaque échantillon est traité individuellement)
dada() : applique les modèles d’erreurs pour corriger les séquences
```{r, cache=TRUE}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)#reads forward
```
```{r, cache=TRUE}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)#reads reverse
```
Affichage du résultat de denoising du premier élément de la liste forward :
```{r, cache=TRUE}
dadaFs[[1]]
```
Après correction des erreurs, DADA2 a identifié 128 séquences uniques réelles (ASV) à partir des 1979 séquences uniques du premier échantillon.

## Fusion des paire de reads (forward et reverse)

Fusion des paires de read F/R en une séquence complète (contigs) -> seules les paires ayant un chevauchement cohérent et suffisant (au moins 12 nucléotides) sont conservées :
```{r, cache=TRUE}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)#mergePairs compare les régions de chevauchement des reads F/R
#mergers = liste de data.frame contenant les séquences et leur abondance
head(mergers[[1]])#vérification contenu du premier échantillon fusionné
```

## Construction de la table des séquences (ASV table)

Construction d’une table de contingence (échantillons × ASV) où chaque cellule contient le nombre de reads conservés :
Chaque ligne correspond à un échantillon.
Chaque colonne correspond à une séquence unique (ASV).
```{r, cache=TRUE}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
La table de séquence est une matrice contenant, ici, 293 ASV.

Vérification de la longueur des séquences obtenues (doit être homogène) :
```{r, cache=TRUE}
table(nchar(getSequences(seqtab)))
dim(seqtab)
```
Les séquences ont environ la taille attendu de la région V4 de l'ARN 16S.

## Suppression des séquences chimériques

Élimination des séquences chimériques (artefacts de PCR) :
La méthode "consensus" compare les séquences entre échantillons pour identifier les chimères
```{r, cache=TRUE}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
Le tableau résultant ne contient que les séquences valides.

Évaluation de la proportion de séquences non chimériques conservées :
```{r, cache=TRUE}
sum(seqtab.nochim)/sum(seqtab)
```
Proportionnellement à leur abondance, seul 4% des séquences sont des chimères (96% sont cosnervées).

## Suivi des pertes de reads à chaque étape

Création d’un tableau récapitulatif du nombre de reads conservées à chaque étape de la pipeline qui permet de visualiser les pertes entre le filtrage, le denoising, la fusion et le retrait des chimères :

```{r, cache=TRUE}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
Ce tableau aide à détecter où des pertes anormales de reads peuvent survenir. Ici, on ne remarque pas de diminution significative entre les étapes.

## Attribution taxonomique

Attribution d’une taxonomie (de Kingdom à Genus) à chaque séquence unique (ASV) pour les identifier à l’aide de la base SILVA (v138.2) :
```{r, cache=TRUE}
taxa <- assignTaxonomy(seqtab.nochim, "~/tutoriel_ADM/silva_nr99_v138.2_toGenus_trainset.fa.gz", multithread=TRUE)
```

Affichage des premières assignations taxonomiques :
```{r, cache=TRUE}
taxa.print <- taxa
rownames(taxa.print) <- NULL
head(taxa.print)
```
Ici, les Bacteroides sont le taxa le plus abondant dans ces échantillons fécaux.

## Vérification de la précision à l’aide de la communauté témoin (Mock= 20 séquences de souches connues) pour controler la fiabilité de la pipeline

Sélection des ASV détectées dans l’échantillon témoin ("Mock") puis comparaison avec les séquences de référence attendues :
```{r, cache=TRUE}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE)
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```
Chargement des séquences de référence de la communauté témoin :
```{r,cache=TRUE}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
```

Vérification du nombre d’ASV correspondant exactement aux séquences attendues :
```{r,cache=TRUE}
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```
Ici, DADA2 donne 20 ASVs qui matchent avec les 20 séquences attendues → la pipeline fonctionne parfaitement.